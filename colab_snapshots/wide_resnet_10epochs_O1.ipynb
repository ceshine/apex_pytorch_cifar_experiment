{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21427,
     "status": "ok",
     "timestamp": 1560296882313,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "FvIdywxKIP0m",
    "outputId": "ab6356a0-07f0-4646-c4d9-315cf8c67d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 11 23:47:48 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5247
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 274769,
     "status": "ok",
     "timestamp": 1560297158434,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "gbpPoyq4Dwe8",
    "outputId": "bb60919e-446e-45fa-b6eb-f86dff1bf904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/tmp/apex'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects:  25% (1/4)   \u001b[K\r",
      "remote: Counting objects:  50% (2/4)   \u001b[K\r",
      "remote: Counting objects:  75% (3/4)   \u001b[K\r",
      "remote: Counting objects: 100% (4/4)   \u001b[K\r",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects:  25% (1/4)   \u001b[K\r",
      "remote: Compressing objects:  50% (2/4)   \u001b[K\r",
      "remote: Compressing objects:  75% (3/4)   \u001b[K\r",
      "remote: Compressing objects: 100% (4/4)   \u001b[K\r",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "Receiving objects:   0% (1/4640)   \r",
      "Receiving objects:   1% (47/4640)   \r",
      "Receiving objects:   2% (93/4640)   \r",
      "Receiving objects:   3% (140/4640)   \r",
      "Receiving objects:   4% (186/4640)   \r",
      "Receiving objects:   5% (232/4640)   \r",
      "Receiving objects:   6% (279/4640)   \r",
      "Receiving objects:   7% (325/4640)   \r",
      "Receiving objects:   8% (372/4640)   \r",
      "Receiving objects:   9% (418/4640)   \r",
      "Receiving objects:  10% (464/4640)   \r",
      "Receiving objects:  11% (511/4640)   \r",
      "Receiving objects:  12% (557/4640)   \r",
      "Receiving objects:  13% (604/4640)   \r",
      "Receiving objects:  14% (650/4640)   \r",
      "Receiving objects:  15% (696/4640)   \r",
      "Receiving objects:  16% (743/4640)   \r",
      "Receiving objects:  17% (789/4640)   \r",
      "Receiving objects:  18% (836/4640)   \r",
      "Receiving objects:  19% (882/4640)   \r",
      "Receiving objects:  20% (928/4640)   \r",
      "Receiving objects:  21% (975/4640)   \r",
      "Receiving objects:  22% (1021/4640)   \r",
      "Receiving objects:  23% (1068/4640)   \r",
      "Receiving objects:  24% (1114/4640)   \r",
      "Receiving objects:  25% (1160/4640)   \r",
      "Receiving objects:  26% (1207/4640)   \r",
      "Receiving objects:  27% (1253/4640)   \r",
      "Receiving objects:  28% (1300/4640)   \r",
      "Receiving objects:  29% (1346/4640)   \r",
      "Receiving objects:  30% (1392/4640)   \r",
      "Receiving objects:  31% (1439/4640)   \r",
      "Receiving objects:  32% (1485/4640)   \r",
      "Receiving objects:  33% (1532/4640)   \r",
      "Receiving objects:  34% (1578/4640)   \r",
      "Receiving objects:  35% (1624/4640)   \r",
      "Receiving objects:  36% (1671/4640)   \r",
      "Receiving objects:  37% (1717/4640)   \r",
      "Receiving objects:  38% (1764/4640)   \r",
      "Receiving objects:  39% (1810/4640)   \r",
      "Receiving objects:  40% (1856/4640)   \r",
      "Receiving objects:  41% (1903/4640)   \r",
      "Receiving objects:  42% (1949/4640)   \r",
      "Receiving objects:  43% (1996/4640)   \r",
      "Receiving objects:  44% (2042/4640)   \r",
      "Receiving objects:  45% (2088/4640)   \r",
      "Receiving objects:  46% (2135/4640)   \r",
      "Receiving objects:  47% (2181/4640)   \r",
      "Receiving objects:  48% (2228/4640)   \r",
      "Receiving objects:  49% (2274/4640)   \r",
      "Receiving objects:  50% (2320/4640)   \r",
      "Receiving objects:  51% (2367/4640)   \r",
      "Receiving objects:  52% (2413/4640)   \r",
      "Receiving objects:  53% (2460/4640)   \r",
      "Receiving objects:  54% (2506/4640)   \r",
      "Receiving objects:  55% (2552/4640)   \r",
      "Receiving objects:  56% (2599/4640)   \r",
      "Receiving objects:  57% (2645/4640)   \r",
      "Receiving objects:  58% (2692/4640)   \r",
      "Receiving objects:  59% (2738/4640)   \r",
      "Receiving objects:  60% (2784/4640)   \r",
      "Receiving objects:  61% (2831/4640)   \r",
      "Receiving objects:  62% (2877/4640)   \r",
      "Receiving objects:  63% (2924/4640)   \r",
      "Receiving objects:  64% (2970/4640)   \r",
      "Receiving objects:  65% (3016/4640)   \r",
      "Receiving objects:  66% (3063/4640)   \r",
      "Receiving objects:  67% (3109/4640)   \r",
      "Receiving objects:  68% (3156/4640)   \r",
      "Receiving objects:  69% (3202/4640)   \r",
      "Receiving objects:  70% (3248/4640)   \r",
      "Receiving objects:  71% (3295/4640)   \r",
      "Receiving objects:  72% (3341/4640)   \r",
      "Receiving objects:  73% (3388/4640)   \r",
      "Receiving objects:  74% (3434/4640)   \r",
      "Receiving objects:  75% (3480/4640)   \r",
      "Receiving objects:  76% (3527/4640)   \r",
      "Receiving objects:  77% (3573/4640)   \r",
      "Receiving objects:  78% (3620/4640)   \r",
      "Receiving objects:  79% (3666/4640)   \r",
      "Receiving objects:  80% (3712/4640)   \r",
      "Receiving objects:  81% (3759/4640)   \r",
      "Receiving objects:  82% (3805/4640)   \r",
      "Receiving objects:  83% (3852/4640)   \r",
      "Receiving objects:  84% (3898/4640)   \r",
      "Receiving objects:  85% (3944/4640)   \r",
      "Receiving objects:  86% (3991/4640)   \r",
      "Receiving objects:  87% (4037/4640)   \r",
      "Receiving objects:  88% (4084/4640)   \r",
      "Receiving objects:  89% (4130/4640)   \r",
      "Receiving objects:  90% (4176/4640)   \r",
      "remote: Total 4640 (delta 0), reused 1 (delta 0), pack-reused 4636\u001b[K\n",
      "Receiving objects:  91% (4223/4640)   \r",
      "Receiving objects:  92% (4269/4640)   \r",
      "Receiving objects:  93% (4316/4640)   \r",
      "Receiving objects:  94% (4362/4640)   \r",
      "Receiving objects:  95% (4408/4640)   \r",
      "Receiving objects:  96% (4455/4640)   \r",
      "Receiving objects:  97% (4501/4640)   \r",
      "Receiving objects:  98% (4548/4640)   \r",
      "Receiving objects:  99% (4594/4640)   \r",
      "Receiving objects: 100% (4640/4640)   \r",
      "Receiving objects: 100% (4640/4640), 8.69 MiB | 21.70 MiB/s, done.\n",
      "Resolving deltas:   0% (0/3012)   \r",
      "Resolving deltas:   1% (35/3012)   \r",
      "Resolving deltas:   3% (99/3012)   \r",
      "Resolving deltas:   4% (138/3012)   \r",
      "Resolving deltas:   5% (152/3012)   \r",
      "Resolving deltas:   6% (182/3012)   \r",
      "Resolving deltas:   7% (228/3012)   \r",
      "Resolving deltas:   8% (241/3012)   \r",
      "Resolving deltas:   9% (279/3012)   \r",
      "Resolving deltas:  10% (308/3012)   \r",
      "Resolving deltas:  11% (358/3012)   \r",
      "Resolving deltas:  12% (372/3012)   \r",
      "Resolving deltas:  13% (403/3012)   \r",
      "Resolving deltas:  15% (454/3012)   \r",
      "Resolving deltas:  16% (493/3012)   \r",
      "Resolving deltas:  17% (521/3012)   \r",
      "Resolving deltas:  18% (546/3012)   \r",
      "Resolving deltas:  19% (574/3012)   \r",
      "Resolving deltas:  20% (603/3012)   \r",
      "Resolving deltas:  21% (633/3012)   \r",
      "Resolving deltas:  22% (672/3012)   \r",
      "Resolving deltas:  23% (709/3012)   \r",
      "Resolving deltas:  28% (858/3012)   \r",
      "Resolving deltas:  29% (875/3012)   \r",
      "Resolving deltas:  30% (904/3012)   \r",
      "Resolving deltas:  31% (941/3012)   \r",
      "Resolving deltas:  32% (972/3012)   \r",
      "Resolving deltas:  33% (1019/3012)   \r",
      "Resolving deltas:  34% (1028/3012)   \r",
      "Resolving deltas:  36% (1111/3012)   \r",
      "Resolving deltas:  37% (1121/3012)   \r",
      "Resolving deltas:  38% (1147/3012)   \r",
      "Resolving deltas:  39% (1179/3012)   \r",
      "Resolving deltas:  40% (1210/3012)   \r",
      "Resolving deltas:  41% (1238/3012)   \r",
      "Resolving deltas:  42% (1275/3012)   \r",
      "Resolving deltas:  43% (1298/3012)   \r",
      "Resolving deltas:  44% (1329/3012)   \r",
      "Resolving deltas:  45% (1357/3012)   \r",
      "Resolving deltas:  46% (1389/3012)   \r",
      "Resolving deltas:  47% (1418/3012)   \r",
      "Resolving deltas:  48% (1475/3012)   \r",
      "Resolving deltas:  49% (1476/3012)   \r",
      "Resolving deltas:  50% (1510/3012)   \r",
      "Resolving deltas:  51% (1542/3012)   \r",
      "Resolving deltas:  52% (1581/3012)   \r",
      "Resolving deltas:  53% (1624/3012)   \r",
      "Resolving deltas:  54% (1635/3012)   \r",
      "Resolving deltas:  55% (1663/3012)   \r",
      "Resolving deltas:  57% (1726/3012)   \r",
      "Resolving deltas:  58% (1757/3012)   \r",
      "Resolving deltas:  59% (1788/3012)   \r",
      "Resolving deltas:  60% (1823/3012)   \r",
      "Resolving deltas:  61% (1862/3012)   \r",
      "Resolving deltas:  62% (1871/3012)   \r",
      "Resolving deltas:  63% (1899/3012)   \r",
      "Resolving deltas:  64% (1933/3012)   \r",
      "Resolving deltas:  65% (1970/3012)   \r",
      "Resolving deltas:  66% (1997/3012)   \r",
      "Resolving deltas:  67% (2044/3012)   \r",
      "Resolving deltas:  68% (2072/3012)   \r",
      "Resolving deltas:  69% (2082/3012)   \r",
      "Resolving deltas:  70% (2114/3012)   \r",
      "Resolving deltas:  72% (2188/3012)   \r",
      "Resolving deltas:  73% (2200/3012)   \r",
      "Resolving deltas:  74% (2229/3012)   \r",
      "Resolving deltas:  75% (2276/3012)   \r",
      "Resolving deltas:  77% (2322/3012)   \r",
      "Resolving deltas:  78% (2354/3012)   \r",
      "Resolving deltas:  79% (2380/3012)   \r",
      "Resolving deltas:  80% (2435/3012)   \r",
      "Resolving deltas:  81% (2440/3012)   \r",
      "Resolving deltas:  82% (2470/3012)   \r",
      "Resolving deltas:  83% (2518/3012)   \r",
      "Resolving deltas:  84% (2557/3012)   \r",
      "Resolving deltas:  85% (2589/3012)   \r",
      "Resolving deltas:  86% (2591/3012)   \r",
      "Resolving deltas:  87% (2628/3012)   \r",
      "Resolving deltas:  88% (2658/3012)   \r",
      "Resolving deltas:  89% (2683/3012)   \r",
      "Resolving deltas:  90% (2711/3012)   \r",
      "Resolving deltas:  91% (2742/3012)   \r",
      "Resolving deltas:  92% (2777/3012)   \r",
      "Resolving deltas:  93% (2802/3012)   \r",
      "Resolving deltas:  94% (2832/3012)   \r",
      "Resolving deltas:  95% (2870/3012)   \r",
      "Resolving deltas:  97% (2924/3012)   \r",
      "Resolving deltas:  98% (2956/3012)   \r",
      "Resolving deltas:  99% (2984/3012)   \r",
      "Resolving deltas: 100% (3012/3012)   \r",
      "Resolving deltas: 100% (3012/3012), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:244: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-np_ug05q\n",
      "Created temporary directory: /tmp/pip-req-tracker-nirvpbfz\n",
      "Created requirements tracker '/tmp/pip-req-tracker-nirvpbfz'\n",
      "Created temporary directory: /tmp/pip-install-6i2o0upf\n",
      "Processing /tmp/apex\n",
      "  Created temporary directory: /tmp/pip-req-build-bdfgvw3s\n",
      "  Added file:///tmp/apex to build tracker '/tmp/pip-req-tracker-nirvpbfz'\n",
      "    Running setup.py (path:/tmp/pip-req-build-bdfgvw3s/setup.py) egg_info for package from file:///tmp/apex\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.1.0\n",
      "    running egg_info\n",
      "    creating pip-egg-info/apex.egg-info\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-bdfgvw3s has version 0.1, which satisfies requirement apex==0.1 from file:///tmp/apex\n",
      "  Removed apex==0.1 from file:///tmp/apex from build tracker '/tmp/pip-req-tracker-nirvpbfz'\n",
      "Skipping bdist_wheel for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-3bma6ogj\n",
      "    Running command /usr/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-req-build-bdfgvw3s/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-3bma6ogj/install-record.txt --single-version-externally-managed --compile\n",
      "    torch.__version__  =  1.1.0\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "    Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "    Cuda compilation tools, release 10.0, V10.0.130\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    running build_ext\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_adam_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-3bma6ogj/install-record.txt'\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-bdfgvw3s\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-nirvpbfz'\n",
      "Cloning into '/tmp/src'...\n",
      "remote: Enumerating objects: 43, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 43 (delta 22), reused 37 (delta 16), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (43/43), done.\n",
      "Collecting python-telegram-bot\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/6c/47932a4041ee76650ad1f45a80e1422077e1e99c08a4d7a61cfbe5393d41/python_telegram_bot-11.1.0-py2.py3-none-any.whl (326kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 4.7MB/s \n",
      "\u001b[?25hCollecting pretrainedmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 24.3MB/s \n",
      "\u001b[?25hCollecting cryptography (from python-telegram-bot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/18/c6557f63a6abde34707196fb2cad1c6dc0dbff25a200d5044922496668a4/cryptography-2.7-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 34kB/s \n",
      "\u001b[?25hRequirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (0.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2019.3.9)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.1.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.3.0)\n",
      "Collecting munch (from pretrainedmodels)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/f4/260ec98ea840757a0da09e0ed8135333d59b8dfebe9752a365b04857660a/munch-2.3.2.tar.gz\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
      "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.12.0)\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography->python-telegram-bot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 32.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.12.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.16.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (4.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.19)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->pretrainedmodels) (0.46)\n",
      "Building wheels for collected packages: pretrainedmodels, munch\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
      "  Building wheel for munch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/bf/bc/06a3e1bfe0ab27d2e720ceb3cff3159398d92644c0cec2c125\n",
      "Successfully built pretrainedmodels munch\n",
      "Installing collected packages: asn1crypto, cryptography, python-telegram-bot, munch, pretrainedmodels\n",
      "Successfully installed asn1crypto-0.24.0 cryptography-2.7 munch-2.3.2 pretrainedmodels-0.7.4 python-telegram-bot-11.1.0\n",
      "Collecting https://github.com/ceshine/pytorch_helper_bot/archive/0.1.3.zip\n",
      "\u001b[?25l  Downloading https://github.com/ceshine/pytorch_helper_bot/archive/0.1.3.zip\n",
      "\u001b[K     | 194kB 1.6MB/s\n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from PyTorchHelperBot==0.1.3) (1.1.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from PyTorchHelperBot==0.1.3) (0.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->PyTorchHelperBot==0.1.3) (1.16.4)\n",
      "Building wheels for collected packages: PyTorchHelperBot\n",
      "  Building wheel for PyTorchHelperBot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ths2g4bn/wheels/df/2e/6a/e50750a599f64ec75afc05c5a5e3cf5b77a7e64dc6707a69dd\n",
      "Successfully built PyTorchHelperBot\n",
      "Installing collected packages: PyTorchHelperBot\n",
      "Successfully installed PyTorchHelperBot-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex /tmp/apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /tmp/apex/.\n",
    "!git clone https://github.com/ceshine/apex_pytorch_cifar_experiment /tmp/src\n",
    "!cp /tmp/src/*.py .\n",
    "!pip install python-telegram-bot pretrainedmodels\n",
    "!pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.1.3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 324108,
     "status": "ok",
     "timestamp": 1560297215956,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "fP6MRxC3FFdY",
    "outputId": "47be2eff-638b-48a7-9892-e309321b4c8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e7708038-b34a-4139-8b97-1738e05e55f0\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-e7708038-b34a-4139-8b97-1738e05e55f0\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving telegram_tokens.py to telegram_tokens.py\n",
      "User uploaded file \"telegram_tokens.py\" with length 82 bytes\n"
     ]
    }
   ],
   "source": [
    "# Upload telegram tokens\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBmSSYshHDRQ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from helperbot import (\n",
    "    TriangularLR, BaseBot, WeightDecayOptimizerWrapper,\n",
    "    LearningRateSchedulerCallback\n",
    ")\n",
    "from helperbot.metrics import SoftmaxAccuracy\n",
    "from apex import amp\n",
    "from apex.optimizers import FusedAdam\n",
    "\n",
    "from baseline import (\n",
    "    CifarBot, get_cifar10_dataset,\n",
    "    get_wide_resnet, get_se_resnext,\n",
    "    get_gpu_memory_map\n",
    ")\n",
    "from telegram_tokens import BOT_TOKEN, CHAT_ID\n",
    "from telegram_sender import telegram_sender\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "EPOCHS = 10\n",
    "MODEL_FUNC = get_wide_resnet\n",
    "\n",
    "@telegram_sender(token=BOT_TOKEN, chat_id=CHAT_ID)\n",
    "def train_apex(level):\n",
    "    train_dl, valid_dl = get_cifar10_dataset(batch_size=128)\n",
    "    steps_per_epoch = len(train_dl)\n",
    "\n",
    "    model = MODEL_FUNC()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=0.1,\n",
    "        momentum=0.9, weight_decay=5e-4)\n",
    "#     optimizer = WeightDecayOptimizerWrapper(optim.Adam(\n",
    "#         model.parameters(), lr=1.5e-3), 0.1)    \n",
    "#     optimizer = optim.Adam(\n",
    "#         model.parameters(), lr=1.5e-3, weight_decay=1e-4)\n",
    "    if level != \"O0\":\n",
    "        model, optimizer = amp.initialize(\n",
    "            model, optimizer, opt_level=level\n",
    "        )\n",
    "    \n",
    "    n_epochs = EPOCHS\n",
    "    n_steps = n_epochs * steps_per_epoch\n",
    "    bot = CifarBot(\n",
    "        log_dir=Path(\".\"), checkpoint_dir=Path(\"/tmp/\"),\n",
    "        model=model, train_loader=train_dl, val_loader=valid_dl,\n",
    "        optimizer=optimizer, echo=True,\n",
    "        avg_window=steps_per_epoch // 3,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        device=DEVICE, clip_grad=10.,\n",
    "        callbacks=[\n",
    "            LearningRateSchedulerCallback(\n",
    "                TriangularLR(\n",
    "                    optimizer, 1000, ratio=5, steps_per_cycle=n_steps\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        metrics=[SoftmaxAccuracy()],\n",
    "        pbar=True,\n",
    "        use_amp=True if level != \"O0\" else False\n",
    "    )\n",
    "    bot.train(\n",
    "        n_steps,\n",
    "        snapshot_interval=steps_per_epoch,\n",
    "        log_interval=steps_per_epoch // 3,\n",
    "        keep_n_snapshots=1\n",
    "    )\n",
    "    print(f\"GPU Memory Used: {get_gpu_memory_map()} MB\")\n",
    "    bot.load_model(bot.best_performers[0][1])\n",
    "    bot.remove_checkpoints(keep=0)\n",
    "    model = MODEL_FUNC().cpu()\n",
    "    model.load_state_dict(bot.model.cpu().state_dict())\n",
    "    torch.save(model, f\"{level}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2500
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762356,
     "status": "ok",
     "timestamp": 1560300014294,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "kDtnODMtI87Z",
    "outputId": "33f0f46e-e35b-407e-c53e-8c125ba97f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 28x10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[06/12/2019 12:09:06 AM]] SEED: 9293\n",
      "[[06/12/2019 12:09:06 AM]] # of parameters: 36,489,290\n",
      "[[06/12/2019 12:09:06 AM]] # of trainable parameters: 36,489,290\n",
      "[[06/12/2019 12:09:06 AM]] Optimizer SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "[[06/12/2019 12:09:06 AM]] Batches per epoch: 390\n",
      "[[06/12/2019 12:09:06 AM]] ====================Epoch 1====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[06/12/2019 12:10:03 AM]] Step 130: train 1.976669 lr: 1.977e-02\n",
      "[[06/12/2019 12:11:02 AM]] Step 260: train 1.572628 lr: 3.975e-02\n",
      "[[06/12/2019 12:12:01 AM]] Step 390: train 1.309087 lr: 5.973e-02\n",
      "100%|██████████| 40/40 [00:10<00:00,  3.98it/s]\n",
      "[[06/12/2019 12:12:11 AM]] Criterion loss: 1.53847215\n",
      "[[06/12/2019 12:12:11 AM]] accuracy: 49.55%\n",
      "[[06/12/2019 12:12:11 AM]] Snapshot metric 1.53847215\n",
      "[[06/12/2019 12:12:11 AM]] Saving checkpoint /tmp/snapshot_basebot_1.53847215_390.pth...\n",
      "[[06/12/2019 12:12:11 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:12:11 AM]] ====================Epoch 2====================\n",
      "[[06/12/2019 12:13:11 AM]] Step 520: train 1.134857 lr: 7.971e-02\n",
      "[[06/12/2019 12:14:10 AM]] Step 650: train 1.075486 lr: 9.969e-02\n",
      "[[06/12/2019 12:15:08 AM]] Step 780: train 1.001067 lr: 9.607e-02\n",
      "100%|██████████| 40/40 [00:10<00:00,  4.00it/s]\n",
      "[[06/12/2019 12:15:18 AM]] Criterion loss: 1.24838937\n",
      "[[06/12/2019 12:15:18 AM]] accuracy: 59.44%\n",
      "[[06/12/2019 12:15:18 AM]] Snapshot metric 1.24838937\n",
      "[[06/12/2019 12:15:18 AM]] Saving checkpoint /tmp/snapshot_basebot_1.24838937_780.pth...\n",
      "[[06/12/2019 12:15:19 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:15:19 AM]] ====================Epoch 3====================\n",
      "[[06/12/2019 12:16:18 AM]] Step 910: train 0.896785 lr: 9.207e-02\n",
      "[[06/12/2019 12:17:17 AM]] Step 1040: train 0.845359 lr: 8.807e-02\n",
      "[[06/12/2019 12:18:16 AM]] Step 1170: train 0.787709 lr: 8.408e-02\n",
      "100%|██████████| 40/40 [00:10<00:00,  3.99it/s]\n",
      "[[06/12/2019 12:18:26 AM]] Criterion loss: 1.14616452\n",
      "[[06/12/2019 12:18:26 AM]] accuracy: 64.72%\n",
      "[[06/12/2019 12:18:26 AM]] Snapshot metric 1.14616452\n",
      "[[06/12/2019 12:18:26 AM]] Saving checkpoint /tmp/snapshot_basebot_1.14616452_1170.pth...\n",
      "[[06/12/2019 12:18:26 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:18:26 AM]] ====================Epoch 4====================\n",
      "[[06/12/2019 12:19:25 AM]] Step 1300: train 0.741576 lr: 8.008e-02\n",
      "[[06/12/2019 12:20:24 AM]] Step 1430: train 0.692126 lr: 7.609e-02\n",
      "[[06/12/2019 12:21:23 AM]] Step 1560: train 0.652590 lr: 7.209e-02\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.01it/s]\n",
      "[[06/12/2019 12:21:33 AM]] Criterion loss: 1.57268308\n",
      "[[06/12/2019 12:21:33 AM]] accuracy: 60.48%\n",
      "[[06/12/2019 12:21:33 AM]] Snapshot metric 1.57268308\n",
      "[[06/12/2019 12:21:33 AM]] Saving checkpoint /tmp/snapshot_basebot_1.57268308_1560.pth...\n",
      "[[06/12/2019 12:21:33 AM]] ====================Epoch 5====================\n",
      "[[06/12/2019 12:22:32 AM]] Step 1690: train 0.619827 lr: 6.809e-02\n",
      "[[06/12/2019 12:23:31 AM]] Step 1820: train 0.612097 lr: 6.410e-02\n",
      "[[06/12/2019 12:24:29 AM]] Step 1950: train 0.560926 lr: 6.010e-02\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.02it/s]\n",
      "[[06/12/2019 12:24:39 AM]] Criterion loss: 1.07180509\n",
      "[[06/12/2019 12:24:39 AM]] accuracy: 70.03%\n",
      "[[06/12/2019 12:24:39 AM]] Snapshot metric 1.07180509\n",
      "[[06/12/2019 12:24:39 AM]] Saving checkpoint /tmp/snapshot_basebot_1.07180509_1950.pth...\n",
      "[[06/12/2019 12:24:40 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:24:40 AM]] ====================Epoch 6====================\n",
      "[[06/12/2019 12:25:39 AM]] Step 2080: train 0.534497 lr: 5.611e-02\n",
      "[[06/12/2019 12:26:37 AM]] Step 2210: train 0.521629 lr: 5.211e-02\n",
      "[[06/12/2019 12:27:36 AM]] Step 2340: train 0.508297 lr: 4.811e-02\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.04it/s]\n",
      "[[06/12/2019 12:27:46 AM]] Criterion loss: 0.68465865\n",
      "[[06/12/2019 12:27:46 AM]] accuracy: 78.55%\n",
      "[[06/12/2019 12:27:46 AM]] Snapshot metric 0.68465865\n",
      "[[06/12/2019 12:27:46 AM]] Saving checkpoint /tmp/snapshot_basebot_0.68465865_2340.pth...\n",
      "[[06/12/2019 12:27:46 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:27:46 AM]] ====================Epoch 7====================\n",
      "[[06/12/2019 12:28:45 AM]] Step 2470: train 0.474321 lr: 4.412e-02\n",
      "[[06/12/2019 12:29:44 AM]] Step 2600: train 0.443561 lr: 4.012e-02\n",
      "[[06/12/2019 12:30:42 AM]] Step 2730: train 0.446550 lr: 3.613e-02\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.05it/s]\n",
      "[[06/12/2019 12:30:52 AM]] Criterion loss: 0.52199413\n",
      "[[06/12/2019 12:30:52 AM]] accuracy: 82.86%\n",
      "[[06/12/2019 12:30:52 AM]] Snapshot metric 0.52199413\n",
      "[[06/12/2019 12:30:52 AM]] Saving checkpoint /tmp/snapshot_basebot_0.52199413_2730.pth...\n",
      "[[06/12/2019 12:30:52 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:30:52 AM]] ====================Epoch 8====================\n",
      "[[06/12/2019 12:31:51 AM]] Step 2860: train 0.388773 lr: 3.213e-02\n",
      "[[06/12/2019 12:32:50 AM]] Step 2990: train 0.395653 lr: 2.813e-02\n",
      "[[06/12/2019 12:33:48 AM]] Step 3120: train 0.380364 lr: 2.414e-02\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.03it/s]\n",
      "[[06/12/2019 12:33:58 AM]] Criterion loss: 0.55339090\n",
      "[[06/12/2019 12:33:58 AM]] accuracy: 83.33%\n",
      "[[06/12/2019 12:33:58 AM]] Snapshot metric 0.55339090\n",
      "[[06/12/2019 12:33:58 AM]] Saving checkpoint /tmp/snapshot_basebot_0.55339090_3120.pth...\n",
      "[[06/12/2019 12:33:58 AM]] ====================Epoch 9====================\n",
      "[[06/12/2019 12:34:57 AM]] Step 3250: train 0.321501 lr: 2.014e-02\n",
      "[[06/12/2019 12:35:56 AM]] Step 3380: train 0.317944 lr: 1.615e-02\n",
      "[[06/12/2019 12:36:54 AM]] Step 3510: train 0.304175 lr: 1.215e-02\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.05it/s]\n",
      "[[06/12/2019 12:37:04 AM]] Criterion loss: 0.49314545\n",
      "[[06/12/2019 12:37:04 AM]] accuracy: 85.25%\n",
      "[[06/12/2019 12:37:04 AM]] Snapshot metric 0.49314545\n",
      "[[06/12/2019 12:37:04 AM]] Saving checkpoint /tmp/snapshot_basebot_0.49314545_3510.pth...\n",
      "[[06/12/2019 12:37:05 AM]] New low\n",
      "\n",
      "[[06/12/2019 12:37:05 AM]] ====================Epoch 10====================\n",
      "[[06/12/2019 12:38:04 AM]] Step 3640: train 0.257379 lr: 8.153e-03\n",
      "[[06/12/2019 12:39:02 AM]] Step 3770: train 0.250110 lr: 4.157e-03\n",
      "[[06/12/2019 12:40:00 AM]] Step 3900: train 0.232140 lr: 1.615e-04\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.04it/s]\n",
      "[[06/12/2019 12:40:10 AM]] Criterion loss: 0.52090138\n",
      "[[06/12/2019 12:40:10 AM]] accuracy: 84.99%\n",
      "[[06/12/2019 12:40:10 AM]] Snapshot metric 0.52090138\n",
      "[[06/12/2019 12:40:10 AM]] Saving checkpoint /tmp/snapshot_basebot_0.52090138_3900.pth...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Used: 4433 MB\n",
      "| Wide-Resnet 28x10\n",
      "CPU times: user 19min 14s, sys: 12min 54s, total: 32min 8s\n",
      "Wall time: 31min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_apex(\"O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVkCgtKUBCQb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "APEX Cifar 10",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
