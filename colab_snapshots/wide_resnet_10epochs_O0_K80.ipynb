{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6420,
     "status": "ok",
     "timestamp": 1560312130543,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "FvIdywxKIP0m",
    "outputId": "6b4102c9-1140-4fb0-b79a-58e3c43ef85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 12 04:02:06 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5247
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 202290,
     "status": "ok",
     "timestamp": 1560312332812,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "gbpPoyq4Dwe8",
    "outputId": "ded0abd7-6b3f-468e-ae29-a58c50aa9bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/tmp/apex'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects:  25% (1/4)   \u001b[K\r",
      "remote: Counting objects:  50% (2/4)   \u001b[K\r",
      "remote: Counting objects:  75% (3/4)   \u001b[K\r",
      "remote: Counting objects: 100% (4/4)   \u001b[K\r",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 4640 (delta 0), reused 1 (delta 0), pack-reused 4636\u001b[K\n",
      "Receiving objects: 100% (4640/4640), 8.69 MiB | 9.38 MiB/s, done.\n",
      "Resolving deltas: 100% (3012/3012), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:244: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-5emvzj75\n",
      "Created temporary directory: /tmp/pip-req-tracker-6ftfv19y\n",
      "Created requirements tracker '/tmp/pip-req-tracker-6ftfv19y'\n",
      "Created temporary directory: /tmp/pip-install-zer_fp0u\n",
      "Processing /tmp/apex\n",
      "  Created temporary directory: /tmp/pip-req-build-ve4v3i9u\n",
      "  Added file:///tmp/apex to build tracker '/tmp/pip-req-tracker-6ftfv19y'\n",
      "    Running setup.py (path:/tmp/pip-req-build-ve4v3i9u/setup.py) egg_info for package from file:///tmp/apex\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.1.0\n",
      "    running egg_info\n",
      "    creating pip-egg-info/apex.egg-info\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-ve4v3i9u has version 0.1, which satisfies requirement apex==0.1 from file:///tmp/apex\n",
      "  Removed apex==0.1 from file:///tmp/apex from build tracker '/tmp/pip-req-tracker-6ftfv19y'\n",
      "Skipping bdist_wheel for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-h9108qh8\n",
      "    Running command /usr/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-req-build-ve4v3i9u/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-h9108qh8/install-record.txt --single-version-externally-managed --compile\n",
      "    torch.__version__  =  1.1.0\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "    Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "    Cuda compilation tools, release 10.0, V10.0.130\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    running build_ext\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_adam_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-h9108qh8/install-record.txt'\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-ve4v3i9u\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-6ftfv19y'\n",
      "Cloning into '/tmp/src'...\n",
      "remote: Enumerating objects: 43, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 43 (delta 22), reused 37 (delta 16), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (43/43), done.\n",
      "Collecting python-telegram-bot\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/6c/47932a4041ee76650ad1f45a80e1422077e1e99c08a4d7a61cfbe5393d41/python_telegram_bot-11.1.0-py2.py3-none-any.whl (326kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 6.5MB/s \n",
      "\u001b[?25hCollecting pretrainedmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 19.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (0.16.0)\n",
      "Collecting cryptography (from python-telegram-bot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/18/c6557f63a6abde34707196fb2cad1c6dc0dbff25a200d5044922496668a4/cryptography-2.7-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 38.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2019.3.9)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.1.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.3.0)\n",
      "Collecting munch (from pretrainedmodels)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/f4/260ec98ea840757a0da09e0ed8135333d59b8dfebe9752a365b04857660a/munch-2.3.2.tar.gz\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
      "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.12.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.12.3)\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography->python-telegram-bot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 27.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.16.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (4.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.19)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->pretrainedmodels) (0.46)\n",
      "Building wheels for collected packages: pretrainedmodels, munch\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
      "  Building wheel for munch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/bf/bc/06a3e1bfe0ab27d2e720ceb3cff3159398d92644c0cec2c125\n",
      "Successfully built pretrainedmodels munch\n",
      "Installing collected packages: asn1crypto, cryptography, python-telegram-bot, munch, pretrainedmodels\n",
      "Successfully installed asn1crypto-0.24.0 cryptography-2.7 munch-2.3.2 pretrainedmodels-0.7.4 python-telegram-bot-11.1.0\n",
      "Collecting https://github.com/ceshine/pytorch_helper_bot/archive/0.1.3.zip\n",
      "\u001b[?25l  Downloading https://github.com/ceshine/pytorch_helper_bot/archive/0.1.3.zip\n",
      "\u001b[K     \\ 225kB 1.2MB/s\n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from PyTorchHelperBot==0.1.3) (1.1.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from PyTorchHelperBot==0.1.3) (0.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->PyTorchHelperBot==0.1.3) (1.16.4)\n",
      "Building wheels for collected packages: PyTorchHelperBot\n",
      "  Building wheel for PyTorchHelperBot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7164kcj4/wheels/df/2e/6a/e50750a599f64ec75afc05c5a5e3cf5b77a7e64dc6707a69dd\n",
      "Successfully built PyTorchHelperBot\n",
      "Installing collected packages: PyTorchHelperBot\n",
      "Successfully installed PyTorchHelperBot-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex /tmp/apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /tmp/apex/.\n",
    "!git clone https://github.com/ceshine/apex_pytorch_cifar_experiment /tmp/src\n",
    "!cp /tmp/src/*.py .\n",
    "!pip install python-telegram-bot pretrainedmodels\n",
    "!pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.1.3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10674,
     "status": "ok",
     "timestamp": 1560312347270,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "fP6MRxC3FFdY",
    "outputId": "6b493c25-b0eb-4b4a-9dde-ce144c9c88c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-6262788d-b14a-4d2e-a337-c2643af794d7\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-6262788d-b14a-4d2e-a337-c2643af794d7\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving telegram_tokens.py to telegram_tokens.py\n",
      "User uploaded file \"telegram_tokens.py\" with length 82 bytes\n"
     ]
    }
   ],
   "source": [
    "# Upload telegram tokens\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBmSSYshHDRQ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from helperbot import (\n",
    "    TriangularLR, BaseBot, WeightDecayOptimizerWrapper,\n",
    "    LearningRateSchedulerCallback\n",
    ")\n",
    "from helperbot.metrics import SoftmaxAccuracy\n",
    "from apex import amp\n",
    "from apex.optimizers import FusedAdam\n",
    "\n",
    "from baseline import (\n",
    "    CifarBot, get_cifar10_dataset,\n",
    "    get_wide_resnet, get_se_resnext,\n",
    "    get_gpu_memory_map\n",
    ")\n",
    "from telegram_tokens import BOT_TOKEN, CHAT_ID\n",
    "from telegram_sender import telegram_sender\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "EPOCHS = 10\n",
    "MODEL_FUNC = get_wide_resnet\n",
    "\n",
    "@telegram_sender(token=BOT_TOKEN, chat_id=CHAT_ID)\n",
    "def train_apex(level):\n",
    "    train_dl, valid_dl = get_cifar10_dataset(batch_size=128)\n",
    "    steps_per_epoch = len(train_dl)\n",
    "\n",
    "    model = MODEL_FUNC()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=0.1,\n",
    "        momentum=0.9, weight_decay=5e-4)\n",
    "#     optimizer = WeightDecayOptimizerWrapper(optim.Adam(\n",
    "#         model.parameters(), lr=1.5e-3), 0.1)    \n",
    "#     optimizer = optim.Adam(\n",
    "#         model.parameters(), lr=1.5e-3, weight_decay=1e-4)\n",
    "    if level != \"O0\":\n",
    "        model, optimizer = amp.initialize(\n",
    "            model, optimizer, opt_level=level\n",
    "        )\n",
    "    \n",
    "    n_epochs = EPOCHS\n",
    "    n_steps = n_epochs * steps_per_epoch\n",
    "    bot = CifarBot(\n",
    "        log_dir=Path(\".\"), checkpoint_dir=Path(\"/tmp/\"),\n",
    "        model=model, train_loader=train_dl, val_loader=valid_dl,\n",
    "        optimizer=optimizer, echo=True,\n",
    "        avg_window=steps_per_epoch // 3,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        device=DEVICE, clip_grad=10.,\n",
    "        callbacks=[\n",
    "            LearningRateSchedulerCallback(\n",
    "                TriangularLR(\n",
    "                    optimizer, 1000, ratio=5, steps_per_cycle=n_steps\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        metrics=[SoftmaxAccuracy()],\n",
    "        pbar=True,\n",
    "        use_amp=True if level != \"O0\" else False\n",
    "    )\n",
    "    bot.train(\n",
    "        n_steps,\n",
    "        snapshot_interval=steps_per_epoch,\n",
    "        log_interval=steps_per_epoch // 3,\n",
    "        keep_n_snapshots=1\n",
    "    )\n",
    "    print(f\"GPU Memory Used: {get_gpu_memory_map()} MB\")\n",
    "    bot.load_model(bot.best_performers[0][1])\n",
    "    bot.remove_checkpoints(keep=0)\n",
    "    model = MODEL_FUNC().cpu()\n",
    "    model.load_state_dict(bot.model.cpu().state_dict())\n",
    "    torch.save(model, f\"{level}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2223
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 288523,
     "status": "ok",
     "timestamp": 1560318576910,
     "user": {
      "displayName": "Ceshine Lee",
      "photoUrl": "https://lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjMk/9cAibppwQtE/s64/photo.jpg",
      "userId": "15252481341963167741"
     },
     "user_tz": -480
    },
    "id": "kDtnODMtI87Z",
    "outputId": "0b810d73-c15f-4ba3-de64-303c02ee8ab7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:05, 28469542.76it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "| Wide-Resnet 28x10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[06/12/2019 04:06:45 AM]] SEED: 9293\n",
      "[[06/12/2019 04:06:45 AM]] # of parameters: 36,489,290\n",
      "[[06/12/2019 04:06:45 AM]] # of trainable parameters: 36,489,290\n",
      "[[06/12/2019 04:06:45 AM]] Optimizer SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "[[06/12/2019 04:06:45 AM]] Batches per epoch: 390\n",
      "[[06/12/2019 04:06:45 AM]] ====================Epoch 1====================\n",
      "[[06/12/2019 04:09:50 AM]] Step 130: train 1.979096 lr: 1.977e-02\n",
      "[[06/12/2019 04:12:54 AM]] Step 260: train 1.575693 lr: 3.975e-02\n",
      "[[06/12/2019 04:15:59 AM]] Step 390: train 1.296550 lr: 5.973e-02\n",
      "100%|██████████| 40/40 [01:05<00:00,  1.63s/it]\n",
      "[[06/12/2019 04:17:04 AM]] Criterion loss: 1.70243775\n",
      "[[06/12/2019 04:17:04 AM]] accuracy: 46.49%\n",
      "[[06/12/2019 04:17:04 AM]] Snapshot metric 1.70243775\n",
      "[[06/12/2019 04:17:04 AM]] Saving checkpoint /tmp/snapshot_basebot_1.70243775_390.pth...\n",
      "[[06/12/2019 04:17:05 AM]] New low\n",
      "\n",
      "[[06/12/2019 04:17:05 AM]] ====================Epoch 2====================\n",
      "[[06/12/2019 04:20:09 AM]] Step 520: train 1.128377 lr: 7.971e-02\n",
      "[[06/12/2019 04:23:14 AM]] Step 650: train 1.087731 lr: 9.969e-02\n",
      "[[06/12/2019 04:26:18 AM]] Step 780: train 1.000249 lr: 9.607e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.61s/it]\n",
      "[[06/12/2019 04:27:22 AM]] Criterion loss: 1.42472058\n",
      "[[06/12/2019 04:27:22 AM]] accuracy: 57.69%\n",
      "[[06/12/2019 04:27:22 AM]] Snapshot metric 1.42472058\n",
      "[[06/12/2019 04:27:22 AM]] Saving checkpoint /tmp/snapshot_basebot_1.42472058_780.pth...\n",
      "[[06/12/2019 04:27:23 AM]] New low\n",
      "\n",
      "[[06/12/2019 04:27:23 AM]] ====================Epoch 3====================\n",
      "[[06/12/2019 04:30:27 AM]] Step 910: train 0.896759 lr: 9.207e-02\n",
      "[[06/12/2019 04:33:30 AM]] Step 1040: train 0.836980 lr: 8.807e-02\n",
      "[[06/12/2019 04:36:34 AM]] Step 1170: train 0.787364 lr: 8.408e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 04:37:38 AM]] Criterion loss: 0.96390047\n",
      "[[06/12/2019 04:37:38 AM]] accuracy: 68.27%\n",
      "[[06/12/2019 04:37:38 AM]] Snapshot metric 0.96390047\n",
      "[[06/12/2019 04:37:38 AM]] Saving checkpoint /tmp/snapshot_basebot_0.96390047_1170.pth...\n",
      "[[06/12/2019 04:37:38 AM]] New low\n",
      "\n",
      "[[06/12/2019 04:37:39 AM]] ====================Epoch 4====================\n",
      "[[06/12/2019 04:40:42 AM]] Step 1300: train 0.735790 lr: 8.008e-02\n",
      "[[06/12/2019 04:43:46 AM]] Step 1430: train 0.682037 lr: 7.609e-02\n",
      "[[06/12/2019 04:46:49 AM]] Step 1560: train 0.651656 lr: 7.209e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 04:47:54 AM]] Criterion loss: 1.13099234\n",
      "[[06/12/2019 04:47:54 AM]] accuracy: 67.26%\n",
      "[[06/12/2019 04:47:54 AM]] Snapshot metric 1.13099234\n",
      "[[06/12/2019 04:47:54 AM]] Saving checkpoint /tmp/snapshot_basebot_1.13099234_1560.pth...\n",
      "[[06/12/2019 04:47:54 AM]] ====================Epoch 5====================\n",
      "[[06/12/2019 04:50:58 AM]] Step 1690: train 0.614642 lr: 6.809e-02\n",
      "[[06/12/2019 04:54:01 AM]] Step 1820: train 0.598381 lr: 6.410e-02\n",
      "[[06/12/2019 04:57:05 AM]] Step 1950: train 0.559620 lr: 6.010e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 04:58:09 AM]] Criterion loss: 1.40914956\n",
      "[[06/12/2019 04:58:09 AM]] accuracy: 63.97%\n",
      "[[06/12/2019 04:58:09 AM]] Snapshot metric 1.40914956\n",
      "[[06/12/2019 04:58:09 AM]] Saving checkpoint /tmp/snapshot_basebot_1.40914956_1950.pth...\n",
      "[[06/12/2019 04:58:10 AM]] ====================Epoch 6====================\n",
      "[[06/12/2019 05:01:14 AM]] Step 2080: train 0.528434 lr: 5.611e-02\n",
      "[[06/12/2019 05:04:17 AM]] Step 2210: train 0.521684 lr: 5.211e-02\n",
      "[[06/12/2019 05:07:21 AM]] Step 2340: train 0.496237 lr: 4.811e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 05:08:25 AM]] Criterion loss: 0.71901872\n",
      "[[06/12/2019 05:08:25 AM]] accuracy: 77.45%\n",
      "[[06/12/2019 05:08:25 AM]] Snapshot metric 0.71901872\n",
      "[[06/12/2019 05:08:25 AM]] Saving checkpoint /tmp/snapshot_basebot_0.71901872_2340.pth...\n",
      "[[06/12/2019 05:08:25 AM]] New low\n",
      "\n",
      "[[06/12/2019 05:08:25 AM]] ====================Epoch 7====================\n",
      "[[06/12/2019 05:11:29 AM]] Step 2470: train 0.459083 lr: 4.412e-02\n",
      "[[06/12/2019 05:14:32 AM]] Step 2600: train 0.439635 lr: 4.012e-02\n",
      "[[06/12/2019 05:17:36 AM]] Step 2730: train 0.449686 lr: 3.613e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 05:18:40 AM]] Criterion loss: 0.56422034\n",
      "[[06/12/2019 05:18:40 AM]] accuracy: 82.05%\n",
      "[[06/12/2019 05:18:40 AM]] Snapshot metric 0.56422034\n",
      "[[06/12/2019 05:18:40 AM]] Saving checkpoint /tmp/snapshot_basebot_0.56422034_2730.pth...\n",
      "[[06/12/2019 05:18:41 AM]] New low\n",
      "\n",
      "[[06/12/2019 05:18:41 AM]] ====================Epoch 8====================\n",
      "[[06/12/2019 05:21:45 AM]] Step 2860: train 0.382079 lr: 3.213e-02\n",
      "[[06/12/2019 05:24:49 AM]] Step 2990: train 0.392405 lr: 2.813e-02\n",
      "[[06/12/2019 05:27:54 AM]] Step 3120: train 0.374285 lr: 2.414e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 05:28:58 AM]] Criterion loss: 0.48868424\n",
      "[[06/12/2019 05:28:58 AM]] accuracy: 85.01%\n",
      "[[06/12/2019 05:28:58 AM]] Snapshot metric 0.48868424\n",
      "[[06/12/2019 05:28:58 AM]] Saving checkpoint /tmp/snapshot_basebot_0.48868424_3120.pth...\n",
      "[[06/12/2019 05:28:58 AM]] New low\n",
      "\n",
      "[[06/12/2019 05:28:58 AM]] ====================Epoch 9====================\n",
      "[[06/12/2019 05:32:03 AM]] Step 3250: train 0.319803 lr: 2.014e-02\n",
      "[[06/12/2019 05:35:07 AM]] Step 3380: train 0.314395 lr: 1.615e-02\n",
      "[[06/12/2019 05:38:11 AM]] Step 3510: train 0.302191 lr: 1.215e-02\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 05:39:16 AM]] Criterion loss: 0.43395262\n",
      "[[06/12/2019 05:39:16 AM]] accuracy: 86.92%\n",
      "[[06/12/2019 05:39:16 AM]] Snapshot metric 0.43395262\n",
      "[[06/12/2019 05:39:16 AM]] Saving checkpoint /tmp/snapshot_basebot_0.43395262_3510.pth...\n",
      "[[06/12/2019 05:39:16 AM]] New low\n",
      "\n",
      "[[06/12/2019 05:39:16 AM]] ====================Epoch 10====================\n",
      "[[06/12/2019 05:42:21 AM]] Step 3640: train 0.254880 lr: 8.153e-03\n",
      "[[06/12/2019 05:45:25 AM]] Step 3770: train 0.244740 lr: 4.157e-03\n",
      "[[06/12/2019 05:48:29 AM]] Step 3900: train 0.227986 lr: 1.615e-04\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n",
      "[[06/12/2019 05:49:33 AM]] Criterion loss: 0.39314977\n",
      "[[06/12/2019 05:49:33 AM]] accuracy: 88.44%\n",
      "[[06/12/2019 05:49:33 AM]] Snapshot metric 0.39314977\n",
      "[[06/12/2019 05:49:33 AM]] Saving checkpoint /tmp/snapshot_basebot_0.39314977_3900.pth...\n",
      "[[06/12/2019 05:49:34 AM]] New low\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Used: 6786 MB\n",
      "| Wide-Resnet 28x10\n",
      "CPU times: user 56min 50s, sys: 46min 13s, total: 1h 43min 3s\n",
      "Wall time: 1h 43min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_apex(\"O0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVkCgtKUBCQb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "APEX Cifar 10",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
